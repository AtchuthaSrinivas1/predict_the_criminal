{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Criminals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation of the XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: ...working... failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - xgboost\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/conda-forge/win-64\n",
      "  - https://conda.anaconda.org/conda-forge/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/win-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/free/win-64\n",
      "  - https://repo.anaconda.com/pkgs/free/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/win-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "  - https://repo.anaconda.com/pkgs/pro/win-64\n",
      "  - https://repo.anaconda.com/pkgs/pro/noarch\n",
      "  - https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "  - https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge xgboost --yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"flow_chart.png\" height=200px width=800px></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 : Frame the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains the answers to private and personal life of people.Given this, we have to predict whether a person is criminal or not.The train data consists of 45718 rows, while the test data consists of 11430 rows.\n",
    "\n",
    "#### Problem Link:https://www.hackerearth.com/challenge/competitive/predict-the-criminal/machine-learning/predict-the-criminal/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 : Obtain Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4b1347f76dde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m      \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m  \u001b[1;31m#to include metrics for evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier      #\n",
    "from sklearn import cross_validation, metrics  #to include metrics for evaluation\n",
    "from sklearn.grid_search import GridSearchCV #to use gridsearchcv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crim_data=pd.read_csv('criminal_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 : Analyze Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERID</th>\n",
       "      <th>IFATHER</th>\n",
       "      <th>NRCH17_2</th>\n",
       "      <th>IRHHSIZ2</th>\n",
       "      <th>IIHHSIZ2</th>\n",
       "      <th>IRKI17_2</th>\n",
       "      <th>IIKI17_2</th>\n",
       "      <th>IRHH65_2</th>\n",
       "      <th>IIHH65_2</th>\n",
       "      <th>PRXRETRY</th>\n",
       "      <th>...</th>\n",
       "      <th>TOOLONG</th>\n",
       "      <th>TROUBUND</th>\n",
       "      <th>PDEN10</th>\n",
       "      <th>COUTYP2</th>\n",
       "      <th>MAIIN102</th>\n",
       "      <th>AIIND102</th>\n",
       "      <th>ANALWT_C</th>\n",
       "      <th>VESTR</th>\n",
       "      <th>VEREP</th>\n",
       "      <th>Criminal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25095143</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3884.805998</td>\n",
       "      <td>40026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13005143</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1627.108106</td>\n",
       "      <td>40015</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67415143</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4344.957980</td>\n",
       "      <td>40024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70925143</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>792.521931</td>\n",
       "      <td>40027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75235143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1518.118526</td>\n",
       "      <td>40001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PERID  IFATHER  NRCH17_2  IRHHSIZ2  IIHHSIZ2  IRKI17_2  IIKI17_2  \\\n",
       "0  25095143        4         2         4         1         3         1   \n",
       "1  13005143        4         1         3         1         2         1   \n",
       "2  67415143        4         1         2         1         2         1   \n",
       "3  70925143        4         0         2         1         1         1   \n",
       "4  75235143        1         0         6         1         4         1   \n",
       "\n",
       "   IRHH65_2  IIHH65_2  PRXRETRY    ...     TOOLONG  TROUBUND  PDEN10  COUTYP2  \\\n",
       "0         1         1        99    ...           1         2       1        1   \n",
       "1         1         1        99    ...           2         2       2        3   \n",
       "2         1         1        99    ...           2         2       2        3   \n",
       "3         1         1        99    ...           2         2       1        1   \n",
       "4         1         1        99    ...           2         2       2        2   \n",
       "\n",
       "   MAIIN102  AIIND102     ANALWT_C  VESTR  VEREP  Criminal  \n",
       "0         2         2  3884.805998  40026      1         0  \n",
       "1         2         2  1627.108106  40015      2         1  \n",
       "2         2         2  4344.957980  40024      1         0  \n",
       "3         2         2   792.521931  40027      1         0  \n",
       "4         2         2  1518.118526  40001      2         0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crim_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45718 entries, 0 to 45717\n",
      "Data columns (total 72 columns):\n",
      "PERID        45718 non-null int64\n",
      "IFATHER      45718 non-null int64\n",
      "NRCH17_2     45718 non-null int64\n",
      "IRHHSIZ2     45718 non-null int64\n",
      "IIHHSIZ2     45718 non-null int64\n",
      "IRKI17_2     45718 non-null int64\n",
      "IIKI17_2     45718 non-null int64\n",
      "IRHH65_2     45718 non-null int64\n",
      "IIHH65_2     45718 non-null int64\n",
      "PRXRETRY     45718 non-null int64\n",
      "PRXYDATA     45718 non-null int64\n",
      "MEDICARE     45718 non-null int64\n",
      "CAIDCHIP     45718 non-null int64\n",
      "CHAMPUS      45718 non-null int64\n",
      "PRVHLTIN     45718 non-null int64\n",
      "GRPHLTIN     45718 non-null int64\n",
      "HLTINNOS     45718 non-null int64\n",
      "HLCNOTYR     45718 non-null int64\n",
      "HLCNOTMO     45718 non-null int64\n",
      "HLCLAST      45718 non-null int64\n",
      "HLLOSRSN     45718 non-null int64\n",
      "HLNVCOST     45718 non-null int64\n",
      "HLNVOFFR     45718 non-null int64\n",
      "HLNVREF      45718 non-null int64\n",
      "HLNVNEED     45718 non-null int64\n",
      "HLNVSOR      45718 non-null int64\n",
      "IRMCDCHP     45718 non-null int64\n",
      "IIMCDCHP     45718 non-null int64\n",
      "IRMEDICR     45718 non-null int64\n",
      "IIMEDICR     45718 non-null int64\n",
      "IRCHMPUS     45718 non-null int64\n",
      "IICHMPUS     45718 non-null int64\n",
      "IRPRVHLT     45718 non-null int64\n",
      "IIPRVHLT     45718 non-null int64\n",
      "IROTHHLT     45718 non-null int64\n",
      "IIOTHHLT     45718 non-null int64\n",
      "HLCALLFG     45718 non-null int64\n",
      "HLCALL99     45718 non-null int64\n",
      "ANYHLTI2     45718 non-null int64\n",
      "IRINSUR4     45718 non-null int64\n",
      "IIINSUR4     45718 non-null int64\n",
      "OTHINS       45718 non-null int64\n",
      "CELLNOTCL    45718 non-null int64\n",
      "CELLWRKNG    45718 non-null int64\n",
      "IRFAMSOC     45718 non-null int64\n",
      "IIFAMSOC     45718 non-null int64\n",
      "IRFAMSSI     45718 non-null int64\n",
      "IIFAMSSI     45718 non-null int64\n",
      "IRFSTAMP     45718 non-null int64\n",
      "IIFSTAMP     45718 non-null int64\n",
      "IRFAMPMT     45718 non-null int64\n",
      "IIFAMPMT     45718 non-null int64\n",
      "IRFAMSVC     45718 non-null int64\n",
      "IIFAMSVC     45718 non-null int64\n",
      "IRWELMOS     45718 non-null int64\n",
      "IIWELMOS     45718 non-null int64\n",
      "IRPINC3      45718 non-null int64\n",
      "IRFAMIN3     45718 non-null int64\n",
      "IIPINC3      45718 non-null int64\n",
      "IIFAMIN3     45718 non-null int64\n",
      "GOVTPROG     45718 non-null int64\n",
      "POVERTY3     45718 non-null int64\n",
      "TOOLONG      45718 non-null int64\n",
      "TROUBUND     45718 non-null int64\n",
      "PDEN10       45718 non-null int64\n",
      "COUTYP2      45718 non-null int64\n",
      "MAIIN102     45718 non-null int64\n",
      "AIIND102     45718 non-null int64\n",
      "ANALWT_C     45718 non-null float64\n",
      "VESTR        45718 non-null int64\n",
      "VEREP        45718 non-null int64\n",
      "Criminal     45718 non-null int64\n",
      "dtypes: float64(1), int64(71)\n",
      "memory usage: 25.1 MB\n"
     ]
    }
   ],
   "source": [
    "crim_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Introduction On the Model Being Used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Ensemble:\n",
    "        It is a collection of predictors which are put together to give the final prediction.This is done beacause a collection of predictors together give better performance than a single predictor.There are two techniques of ensembling:\n",
    "        Bagging:\n",
    "            This involves building independent predictors and combining all the predictors to give the final prediction\n",
    "        Boosting:\n",
    "            This involves building the predictors sequentially rather than building each predictor independently.In these predictors learn from the mistakes commited by previous predictors.\n",
    "    Gradient Boosting:\n",
    "        Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees.One of the widely used algorithms in gradient boosting is XGBoost algorithm.\n",
    "    XGBoost(eXtreme Gradient Boosting):\n",
    "        XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XgBoostClassifier:\n",
    "    It is an implementation of sklearn api for XgBoost Classification.The parameters of the XGBClassifier are:\n",
    "        booster [default=gbtree]:\n",
    "            Select the type of model to run at each iteration.\n",
    "        silent [default=0]:\n",
    "            Silent mode is activated is set to 1, i.e. no running messages will be printed.\n",
    "        nthread [default to maximum number of threads available if not set]:\n",
    "            This is used for parallel processing and number of cores in the system should be entered\n",
    "        eta [default=0.3]:\n",
    "            learning rate in GBM\n",
    "        min_child_weight [default=1]:\n",
    "            Defines the minimum sum of weights of all observations required in a child.\n",
    "        max_depth [default=6]:\n",
    "            The maximum depth of a tree.Used to control over-fitting as higher depth will allow model to learn relations \n",
    "            very specific to a particular sample.\n",
    "        max_leaf_nodes:\n",
    "            The maximum number of terminal nodes or leaves in a tree.Can be defined in place of max_depth.\n",
    "        gamma [default=0]:\n",
    "        A node is split only when the resulting split gives a positive reduction in the loss function.Gamma specifies \n",
    "        the minimum loss reduction required to make a split.\n",
    "        subsample [default=1]:\n",
    "            Denotes the fraction of observations to be randomly samples for each tree.\n",
    "        colsample_bytree [default=1]:\n",
    "            Denotes the fraction of columns to be randomly samples for each tree.\n",
    "        colsample_bylevel [default=1]:\n",
    "            Denotes the subsample ratio of columns for each split, in each level.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 and 05 : Feature Engineering and Model Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"supervised_flow_chart.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(crim_data.drop('Criminal',axis=1), \n",
    "                                                    crim_data['Criminal'], test_size=0.30, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.concat([X_train,y_train],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to estimate the best value of n_estimators and fit the model with the given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        #to get the parameters of xgboost\n",
    "        xgb_param = alg.get_xgb_params() \n",
    "        \n",
    "        #to convert into a datastructure internally used by xgboost for training efficiency \n",
    "        # and speed\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        \n",
    "        #xgb.cv is used to find the number of estimators required for the parameters \n",
    "        # which are set\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, \n",
    "                          num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "                        metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        \n",
    "        #setting the n_estimators parameter using set_params\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "        \n",
    "        print(alg.get_xgb_params())\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Criminal'],eval_metric='auc')\n",
    "    \n",
    "    return alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to get the accuracy of the model on the test data given the features considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(alg,predictors):\n",
    "    dtrain_predictions = alg.predict(X_test[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(X_test[predictors])[:,1]\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(y_test.values, \n",
    "                                                      dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_test.values, \n",
    "                                                           dtrain_predprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to get the feature importances based on the model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_importances(alg):\n",
    "    #to get the feature importances based on xgboost we use fscore\n",
    "    feat_imp = pd.Series(alg._Booster.get_fscore()).sort_values(ascending=False)\n",
    "    print(feat_imp)\n",
    "    \n",
    "    #this shows the feature importances on a bar chart\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'Criminal'\n",
    "IDcol = 'PERID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to return the XGBClassifier object based on the values of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def XgbClass(learning_rate =0.1,n_estimators=1000,max_depth=5,min_child_weight=1,\n",
    "             gamma=0,subsample=0.8,colsample_bytree=0.8):\n",
    "    xgb1 = XGBClassifier(learning_rate=learning_rate,\n",
    "                         n_estimators=n_estimators,\n",
    "                         max_depth=max_depth,\n",
    "                         min_child_weight=min_child_weight,\n",
    "                         gamma=gamma,\n",
    "                         subsample=subsample,\n",
    "                         colsample_bytree=colsample_bytree)\n",
    "    return xgb1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to return the list of predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these are the initial parameters before tuning\n",
    "def drop_features(l):\n",
    "    return [x for x in train.columns if x not in l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Prediction : Use of initial parameters and without feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = drop_features([target, IDcol])\n",
    "xgb1=XgbClass()\n",
    "first_model=modelfit(xgb1, train, predictors)\n",
    "xgb1.fit(train[predictors],train['Criminal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_accuracy(first_model,predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_feature_importances(first_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Prediction : Using intial Parameters and removing features of least importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model after removing the features of least importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropl=['IRWELMOS','MAIIN102','IIPINC3','HLTINNOS','IIHH65_2','TOOLONG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropl_first=dropl+[target,IDcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these are the initial parameters before tuning\n",
    "predictors = drop_features(dropl_first)\n",
    "xgb1 = XgbClass()\n",
    "second_model=modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_accuracy(second_model,predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_feature_importances(second_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Prediction : Again removing the features of least importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropl1=dropl+['IRMCDCHP','HLCLAST','IIKI17_2','IRFAMPMT','IRFSTAMP','ANYHLTI2','IIFAMSVC']\n",
    "dropl_second=dropl_first+['IRMCDCHP','HLCLAST','IIKI17_2','IRFAMPMT','IRFSTAMP','ANYHLTI2',\n",
    "                          'IIFAMSVC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors=drop_features(dropl_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb1=XgbClass()\n",
    "third_model1=modelfit(xgb1,train,predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_accuracy(third_model1,predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06 : Tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RunTestAndSaveResults(features,filename,model):\n",
    "    df1=pd.read_csv('criminal_test.csv')\n",
    "    for i in features:\n",
    "        df1.drop(i,axis=1,inplace=True)\n",
    "    predict=model.predict(df1.drop('PERID',axis=1))\n",
    "    data=pd.DataFrame(df1['PERID'],columns=['PERID'])\n",
    "    data['Criminal']=predict\n",
    "    data.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = drop_features(dropl_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':list(range(3,10,2)),\n",
    " 'min_child_weight':list(range(1,6,2))\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator=XgbClass(n_estimators=48),param_grid =param_test1,\n",
    "                        scoring='roc_auc',n_jobs=-1,iid=False, cv=5)\n",
    "gsearch1.fit(train[predictors],train[target])\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if the best parameters are edge values then we do \n",
    "#gridsearchcv by taking one less and one value more than the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[6,7,8,9],\n",
    " 'min_child_weight':[2,3,4,5]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator=XgbClass(n_estimators=48),param_grid =param_test2,scoring='roc_auc',n_jobs=-1,iid=False, cv=5)\n",
    "gsearch2.fit(train[predictors],train[target])\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb1 = XgbClass(max_depth=8,min_child_weight=4)\n",
    "model=modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_accuracy(model,predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,8)]\n",
    "}\n",
    "gsearch3=GridSearchCV(estimator=XgbClass(n_estimators=48,max_depth=7,min_child_weight=5),\n",
    "                      param_grid =param_test3,scoring='roc_auc',n_jobs=-1,iid=False, cv=5)\n",
    "gsearch3.fit(train[predictors],train[target])\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb1 = XgbClass(max_depth=8,min_child_weight=4,gamma=0.4)\n",
    "model=modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_accuracy(model,predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4=GridSearchCV(estimator=XgbClass(n_estimators=48,max_depth=7,\n",
    "                                         min_child_weight=5,gamma=0),\n",
    "                      param_grid =param_test4,scoring='roc_auc',n_jobs=-1,iid=False, cv=5)\n",
    "gsearch4.fit(train[predictors],train[target])\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb1 = XgbClass(max_depth=8,min_child_weight=4,gamma=0.4,subsample=0.8,colsample_bytree=0.6)\n",
    "model=modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_accuracy(model,predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropl=['IRWELMOS','MAIIN102','IIPINC3','HLTINNOS','IIHH65_2','TOOLONG']\n",
    "dropl =dropl+ ['HLCLAST','IIFAMSVC', 'IIKI17_2', 'ANYHLTI2', 'IRFAMPMT', 'IRFSTAMP', 'IRMCDCHP']\n",
    "RunTestAndSaveResults(dropl,'final_result.csv',third_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07 : Predicting on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function stores the result in required csv file and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RunTestAndSaveResults([],'result.csv',first_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This model is giving high accurancy since we applied feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RunTestAndSaveResults(dropl,'result.csv',second_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#When the features are repeated again and again then overfitting takes place and the accuracy decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RunTestAndSaveResults(dropl1,'result1.csv',third_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
